# ğŸ–¼ï¸ Reconnaissance de Chiffres Manuscrits avec Deep Learning

> ğŸ¯ *Objectif : Apprendre Ã  un ordinateur Ã  reconnaÃ®tre des chiffres Ã©crits Ã  la main â€” comme un enfant apprend Ã  lire les nombres.*

Ce projet contient **deux notebooks Jupyter** qui implÃ©mentent deux types de rÃ©seaux de neurones pour classifier les chiffres manuscrits du cÃ©lÃ¨bre jeu de donnÃ©es **MNIST** :

- **`01-DNN-MNIST.ipynb`** â†’ RÃ©seau de neurones **dense (DNN)** â€” simple, efficace, parfait pour dÃ©buter.
- **`02-CNN-MNIST.ipynb`** â†’ RÃ©seau de neurones **convolutionnel (CNN)** â€” plus puissant, conÃ§u pour les images.

---

## ğŸ§  Pourquoi MNIST ?

Le jeu de donnÃ©es **MNIST** est le â€œHello Worldâ€ du Deep Learning. Il contient :

- âœï¸ **60 000 images** dâ€™entraÃ®nement (chiffres 0 Ã  9 Ã©crits Ã  la main)
- âœï¸ **10 000 images** de test
- ğŸ“ Images en noir et blanc, 28x28 pixels
- ğŸ¯ Objectif : prÃ©dire le chiffre reprÃ©sentÃ© dans chaque image

Câ€™est le terrain dâ€™entraÃ®nement idÃ©al pour comprendre les bases de la classification dâ€™images avec les rÃ©seaux de neurones.

---

## ğŸ‘¥ Pour qui est ce projet ?

| Public | Ce quâ€™il y trouvera |
|--------|----------------------|
| ğŸ‘©â€ğŸ“ **Ã‰tudiants / DÃ©butants en IA** | Un tutoriel Ã©tape par Ã©tape, avec du code simple, des explications claires, et des visualisations pour comprendre comment fonctionne un rÃ©seau de neurones. |
| ğŸ‘¨â€ğŸ« **Enseignants / Formateurs** | Un support pÃ©dagogique complet pour enseigner les DNN et CNN, avec Ã©valuation, historique dâ€™entraÃ®nement, matrices de confusionâ€¦ |
| ğŸ‘©â€ğŸ’» **Data Scientists / DÃ©veloppeurs** | Une implÃ©mentation propre avec Keras/TensorFlow, facile Ã  modifier, Ã©tendre ou comparer. Parfait pour expÃ©rimenter. |
| ğŸ‘” **Curieux / Non-techniciens** | Des explications simples, des images parlantes, et une dÃ©monstration concrÃ¨te de comment les machines â€œvoientâ€ et â€œreconnaissentâ€ les chiffres. |

---

## âš™ï¸ Ce que vous allez apprendre

### âœ… Dans les deux notebooks :
- Charger et normaliser les donnÃ©es MNIST
- Visualiser les images dâ€™entraÃ®nement
- Compiler un modÃ¨le avec `Adam`, `sparse_categorical_crossentropy`, `accuracy`
- EntraÃ®ner le modÃ¨le sur 16 Ã©poques
- Ã‰valuer les performances (prÃ©cision, perte)
- Visualiser lâ€™historique dâ€™entraÃ®nement
- Afficher les prÃ©dictions (bonnes et mauvaises)
- GÃ©nÃ©rer une **matrice de confusion**

### ğŸ§± 01-DNN-MNIST.ipynb â€” RÃ©seau Dense (Fully Connected)
- Architecture simple :
  - `Flatten()` â†’ transformer lâ€™image 28x28 en vecteur de 784 valeurs
  - 2 couches cachÃ©es de 100 neurones avec activation `ReLU`
  - Couche de sortie de 10 neurones avec `softmax` (probabilitÃ©s pour chaque chiffre)
- PrÃ©cision attendue : **~97.7%**

### ğŸ§© 02-CNN-MNIST.ipynb â€” RÃ©seau Convolutionnel
- Architecture plus adaptÃ©e aux images :
  - Couches `Conv2D` â†’ dÃ©tectent les motifs locaux (bords, courbesâ€¦)
  - Couches `MaxPooling2D` â†’ rÃ©duisent la taille tout en conservant les motifs importants
  - Couches `Dropout` â†’ Ã©vitent le surapprentissage
  - Couche `Flatten` + `Dense` â†’ classification finale
- PrÃ©cision attendue : **> 98.5%** (souvent ~99%)

---

## ğŸ“Š Ã‰tapes Techniques RÃ©alisÃ©es

### 1. ğŸ”¢ PrÃ©paration des donnÃ©es
- Normalisation des pixels entre 0 et 1
- Pour le CNN : ajout dâ€™une dimension de canal (`reshape(-1,28,28,1)`)

### 2. ğŸ—ï¸ Construction du modÃ¨le
- Utilisation de `keras.Sequential`
- Choix des activations (`relu`, `softmax`)
- Compilation avec `sparse_categorical_crossentropy` (car labels entiers, pas one-hot)

### 3. ğŸš€ EntraÃ®nement
- `batch_size = 512`
- `epochs = 16`
- Validation sur les donnÃ©es de test en direct

### 4. ğŸ“ˆ Ã‰valuation & Visualisation
- Calcul de la prÃ©cision finale
- Graphique de lâ€™historique (perte et prÃ©cision sur train/test)
- Affichage des prÃ©dictions (vert = bon, rouge = erreur)
- Matrice de confusion normalisÃ©e â†’ voir oÃ¹ le modÃ¨le se trompe le plus

---

## ğŸ§© Technologies & BibliothÃ¨ques UtilisÃ©es

```python
import tensorflow as tf
from tensorflow import keras

import numpy as np
import matplotlib.pyplot as plt

# Utilitaire maison (Ã  adapter si nÃ©cessaire)
import fidle.pwk as pwk  # â†’ plot_images, plot_history, plot_confusion_matrix...
